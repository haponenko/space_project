{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapefile\n",
    "import pupygrib\n",
    "import ogr\n",
    "from osgeo import gdal\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis:\n",
    "    ELEMENTS = ['O3', 'NO2', 'CO']\n",
    "    HEIGHT_DEVIATION = 500\n",
    "    DEGREE_DEVIATION = 0.1\n",
    "    HEIGHT_MAX = 5000\n",
    "\n",
    "    def __init__(self):\n",
    "        self.project_folder = Path(os.path.abspath('')).parent\n",
    "        self.data_folder = self.project_folder / 'data'\n",
    "        self.shp_folder = self.data_folder / 'shp'\n",
    "        self.nc_folder = self.data_folder / 'nc'\n",
    "        \n",
    "    def getDate(self, file_path):\n",
    "        m = re.search(r\"\\d{8}\", file_path)\n",
    "        date = datetime.datetime.strptime(m.group(), '%Y%m%d')\n",
    "        \n",
    "        return date\n",
    "        \n",
    "    def process(self, file_, date):\n",
    "        date_str = date.strftime(\"%Y%m%d\")\n",
    "        with shapefile.Reader(str(file_)) as shp_file:\n",
    "            result_row = {}\n",
    "            result_row['date'] = date_str\n",
    "\n",
    "            records = shp_file.records()\n",
    "            fields = shp_file.fields[1:]\n",
    "            fields_names = [field[0] for field in fields]\n",
    "            \n",
    "            fields_names[3] = 'O3'  # rename Ozone to O3\n",
    "\n",
    "            data = pd.DataFrame(\n",
    "                np.array(records), columns=fields_names\n",
    "            )\n",
    "            data[['StdAltitu']] /= 3.281  # ft to meters\n",
    "\n",
    "            points_x = np.empty(len(records))\n",
    "            points_y = np.empty(len(records))\n",
    "\n",
    "            shp = ogr.Open(str(file_.absolute()))\n",
    "            layer = shp.GetLayer()\n",
    "            i = 0\n",
    "            while i < len(records):\n",
    "                point = layer.GetFeature(i)\n",
    "                geom = point.GetGeometryRef()\n",
    "                points_x[i] = geom.GetPoint(0)[0]\n",
    "                points_y[i] = geom.GetPoint(0)[1]\n",
    "                i += 1\n",
    "\n",
    "            data['lat'] = points_x\n",
    "            data['long'] = points_y\n",
    "\n",
    "            for element in self.ELEMENTS:\n",
    "                data_clean = data.dropna(axis=1, how='all')\n",
    "                if element not in data_clean.columns:\n",
    "                    continue\n",
    "\n",
    "                data_clean = data_clean.dropna(how='any', axis=0, subset=[element])\n",
    "\n",
    "                clean_data_2km = pd.DataFrame()\n",
    "                clean_data_3km = pd.DataFrame()\n",
    "                clean_data_5km = pd.DataFrame()\n",
    "\n",
    "                for index, row in data_clean.iterrows():\n",
    "                    if row['StdAltitu'] > self.HEIGHT_MAX + self.HEIGHT_DEVIATION:\n",
    "                        continue\n",
    "\n",
    "                    nc_date = datetime.datetime.combine(date, datetime.datetime.min.time())\n",
    "                    nc_date += datetime.timedelta(seconds=row['TimeCRef'])\n",
    "                    nc_date_str = nc_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "                    nc = 0\n",
    "                    for file_ in self.nc_folder.iterdir():\n",
    "                        if nc_date_str in file_.name and element in file_.name:\n",
    "                            with Dataset(str(file_), 'r', format='NETCDF4') as nc_:\n",
    "                                nc = nc_\n",
    "                                el = nc.variables[element]\n",
    "                                lons = nc.variables['lon'][:]\n",
    "                                lats = nc.variables['lat'][:]\n",
    "                                heights = nc.variables['height'][:]\n",
    "\n",
    "                                # latitude index\n",
    "                                if np.abs( lats - row['lat'] ).any() > self.DEGREE_DEVIATION:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    lat_id = np.argmin( np.abs( lats - row['lat'] ) )\n",
    "                                # longitude index\n",
    "                                if np.abs( lons - row['long'] ).any() > self.DEGREE_DEVIATION:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    lon_id = np.argmin( np.abs( lons - row['long'] ) )\n",
    "                                # height index\n",
    "                                if np.abs( heights - row['StdAltitu'] ).any() > self.HEIGHT_DEVIATION:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    height_id = np.argmin( np.abs( heights - row['StdAltitu'] ) )\n",
    "\n",
    "                                # time index\n",
    "                                nc_hour = nc_date.strftime(\"%H\")\n",
    "\n",
    "                                if height_id == 5:  # if 2km\n",
    "                                    clean_data_2km = clean_data_2km.append({\n",
    "                                        'nc_data_'+element: float(el[np.int64(nc_hour), height_id, lat_id, lon_id]),\n",
    "                                        element: row[element]\n",
    "                                    }, ignore_index=True)\n",
    "                                elif height_id == 6: # if 3km\n",
    "                                    clean_data_3km = clean_data_3km.append({\n",
    "                                        'nc_data_'+element: float(el[np.int64(nc_hour), height_id, lat_id, lon_id]),\n",
    "                                        element: row[element]\n",
    "                                    }, ignore_index=True)\n",
    "                                elif height_id == 7: # if 5km\n",
    "                                    clean_data_5km = clean_data_5km.append({\n",
    "                                        'nc_data_'+element: float(el[np.int64(nc_hour), height_id, lat_id, lon_id]),\n",
    "                                        element: row[element]\n",
    "                                    }, ignore_index=True)  \n",
    "\n",
    "                                else:\n",
    "                                    continue\n",
    "\n",
    "                    if not nc:\n",
    "                        continue\n",
    "\n",
    "                if not clean_data_2km.empty:\n",
    "                    corr_2km = clean_data_2km['nc_data_' + element].corr(clean_data_2km[element])\n",
    "                    result_row[element+'_2km'] = corr_2km\n",
    "                    result_row['dots_'+element+'_2km'] = len(clean_data_2km.index)\n",
    "                if not clean_data_3km.empty:\n",
    "                    corr_3km = clean_data_3km['nc_data_' + element].corr(clean_data_3km[element])\n",
    "                    result_row[element+'_3km'] = corr_3km\n",
    "                    result_row['dots_'+element+'_3km'] = len(clean_data_3km.index)\n",
    "                if not clean_data_5km.empty:\n",
    "                    corr_5km = clean_data_5km['nc_data_' + element].corr(clean_data_5km[element])\n",
    "                    result_row[element+'_5km'] = corr_5km\n",
    "                    result_row['dots_'+element+'_5km'] = len(clean_data_5km.index)\n",
    "        return result_row\n",
    "\n",
    "    def analyse(self, date: datetime.date = None):\n",
    "        # Get data\n",
    "        result_data = pd.DataFrame([], columns=['date'])\n",
    "        data = []\n",
    "        if date:\n",
    "            date_str = date.strftime(\"%Y%m%d\")\n",
    "            for file_ in self.shp_folder.iterdir():\n",
    "                if date_str in file_.name and file_.suffix == '.shp':\n",
    "                    result_row = self.process(file_, date)      \n",
    "                    result_data = result_data.append(result_row, ignore_index=True)\n",
    "        else:\n",
    "            for file_ in self.shp_folder.iterdir():\n",
    "                if file_.suffix == '.shp':\n",
    "                    date = self.getDate(str(file_))\n",
    "                    result_row = self.process(file_, date)      \n",
    "                    result_data = result_data.append(result_row, ignore_index=True)\n",
    "                \n",
    "        return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date\n",
      "0   20160112\n",
      "1   20160114\n",
      "2   20160215\n",
      "3   20151130\n",
      "4   20151202\n",
      "5   20160113\n",
      "6   20151201\n",
      "7   20160215\n",
      "8   20151201\n",
      "9   20160113\n",
      "10  20160216\n"
     ]
    }
   ],
   "source": [
    "a = Analysis()\n",
    "d = a.analyse()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
